# MIA on a Binary Classifier â€“ Adult Income (PyTorch)

This repository contains the implementation and evaluation of a neural network trained on the **Adult Income dataset**, developed as part of a **Data Protection / Machine Learning** university project.

The project has two goals:

1. Build a **reproducible binary classification pipeline** on tabular personal data.
2. Run a **Membership Inference Attack (MIA)** pipeline (shadow-model based) to analyze privacy-related behavior.


---

## ğŸ“Š Dataset

**Adult Income dataset** (`adult.csv`) contains demographic and socio-economic attributes (age, education, occupation, etc.) and a binary target variable indicating whether an individual earns more than **$50K/year**.

Key properties:

- Mixed numerical and categorical features  
- Moderate class imbalance  
- Common benchmark for tabular classification  
- Includes high-cardinality / identifier-like attributes (e.g., `name`, `ssn`, `zip`) because the dataset was provided as-is by the course  


---

## ğŸ”§ Preprocessing Pipeline (Target Model)

The preprocessing strategy is intentionally simple, transparent, and reproducible:

1. Removal of missing values (if present in the dataset version)
2. Encoding of categorical features using `LabelEncoder`
3. Standardization using `StandardScaler` on the full feature matrix `X`
4. Conversion to `float32`
5. Train / test split with `train_test_split(test_size=0.2, random_state=42)`

**Important note:**  
The target model training code (`model.py`) performs `LabelEncoder` + `StandardScaler` **before** the train/test split.  
This is kept **as-is** to remain consistent with the original training pipeline and saved target model.


---

## ğŸ§  Model Architecture (Binary Classifier)

All models are implemented in **PyTorch** using an MLP architecture.

Even though the task is binary, the target model outputs **2 logits**:

- Class 0: `<=50K`
- Class 1: `>50K`

Architecture (Version 2 / target model):

Input â†’ Linear(128) â†’ ReLU â†’ Linear(64) â†’ ReLU â†’ Linear(2)


---

## âœ… Version 1 â€“ Lightweight Baseline Model

**File:** `version1.py`

Configuration:

- Dataset size: ~5,000 samples
- Hidden layer: 16 neurons
- Activation: ReLU
- Epochs: ~20
- CPU-only training
- Same simple preprocessing approach

Result:

- Accuracy â‰ˆ **0.754** (75.4%)

Interpretation:

- Stable baseline
- Limited capacity, minimal complexity
- Good starting point for comparisons


---

## ğŸš€ Version 2 â€“ Extended Model (Main Target)

**File:** `model.py`  
**Saved model:** `adult_mlp_model.pth`

Configuration:

- Dataset size: ~30k samples (or full usable subset)
- Hidden layers: **128 â†’ 64**
- Activation: ReLU
- Epochs: ~80
- Same preprocessing and evaluation protocol as Version 1

Observed test performance during training:

- Accuracy â‰ˆ **0.78â€“0.80** (example run: ~0.783â€“0.789)

This model is used as the **TARGET model** for membership inference experiments.


---

## ğŸ§ª Membership Inference Attack (Shadow-Model Based)

We implemented a shadow-model MIA workflow inspired by the classic approach used in academic literature (shadow models + attack model trained on model outputs).

### High-level idea

1. Train multiple shadow models on data from the same distribution.
2. For each shadow model, collect â€œattack featuresâ€ on:
   - points used for training (**IN**, member=1)
   - points not used for training (**OUT**, member=0)
3. Train an attack classifier that predicts membership from these features.
4. Evaluate the attack on the real **TARGET** model.


---

## ğŸ“ Data Splits Used for MIA

We created two main partitions from the original dataset:

- `adulti_buono.csv`  
  Used to train the **TARGET** model (â€œgood modelâ€, binary classifier)

- `shadows/adulti_shadow.csv`  
  Held-out pool used only for shadow models / non-membership sets

Metadata files:

- `adulti_split_meta.json`
- `adulti_buono_indices.csv`
- `adulti_shadow_indices.csv`


---

## ğŸ•µï¸ Shadow Models (n = 10)

Shadow splits are stored under:

`shadows/shadow_splits_bundle/shadow_splits/`

Each shadow `i` has:

- `shadow_0i_train.csv`  (IN set for that shadow)
- `shadow_0i_out.csv`    (OUT set for that shadow)

Typical size per shadow:

- train â‰ˆ 6033  
- out â‰ˆ 6033


---

## ğŸ“¦ Attack Datasets

### 1) Attack TRAIN dataset (from shadow models)

Generated by:

`shadows/shadow_splits_bundle/shadow_splits/mia_train_shadows.py`

Output:

- `shadows/attack_train_from_shadows.csv`

Content (per record):

- `p_hat`  : predicted probability of class 1 (membership feature)
- `loss`   : per-sample loss (membership feature)
- `member` : 1 if IN, 0 if OUT
- `true_label`, `shadow_id` (debug / analysis support)

Generation summary (10 shadows):

- Total rows: **120,660**  
  (10 Ã— (6033 IN + 6033 OUT))


### 2) Attack TEST dataset (from target model)

Generated by:

`mia_make_attack_test_from_target.py`

Output:

- `shadows/attack_test_from_target.csv`

IN/OUT definition for target evaluation:

- IN (member=1)  : `X_train` from `train_test_split(..., test_size=0.2, random_state=42)`
- OUT (member=0) : `X_test`  from the same split

Total rows:

- **18,098** (= 14,478 IN + 3,620 OUT)

Compatibility note (2 logits â†’ 1 membership logit):

- The target model outputs 2 logits, so we convert them to a single logit for membership features:
  `logit_single = logit_class1 - logit_class0`
- Then:
  `p_hat = sigmoid(logit_single)`
  `loss = BCEWithLogitsLoss(logit_single, y)`


---

## ğŸ¯ Attack Model Training & Results

### Attack model: Logistic Regression (simple & defendable)

Script:

- `attack_model.py` (Logistic Regression on `[p_hat, loss]`)

Result on TARGET test set:

- Accuracy â‰ˆ **0.4168**
- ROC-AUC â‰ˆ **0.4974** (â‰ˆ random)


### Attack model per-class (closer to the paper approach)

Script:

- `attack_model_per_class.py`

Per-class AUC:

- class 0: ~0.5040
- class 1: ~0.4928

Final aggregated:

- ROC-AUC â‰ˆ **0.4983**
- Accuracy â‰ˆ **0.3922**

Interpretation:

- With the current feature set (`p_hat`, `loss`) and current training setup, the membership inference attack does **not** generalize to the target (AUC â‰ˆ 0.5).
- Next step (planned): measure target generalization gap (train vs test) and/or align shadow training more closely to target to test whether leakage increases.


---

## ğŸ“ Repository Structure (Current)

.
â”œâ”€â”€ adult.csv
â”œâ”€â”€ adulti_buono.csv
â”œâ”€â”€ adulti_buono_indices.csv
â”œâ”€â”€ adulti_shadow_indices.csv
â”œâ”€â”€ adulti_split_meta.json
â”œâ”€â”€ adult_mlp_model.pth
â”œâ”€â”€ model.py                  # Version 2 / main target model
â”œâ”€â”€ version1.py               # Version 1 baseline
â”œâ”€â”€ inizio_blocco.py
â”œâ”€â”€ mia_make_attack_test_from_target.py
â”œâ”€â”€ attack_model.py
â”œâ”€â”€ attack_model_per_class.py
â”œâ”€â”€ shadows/
â”‚   â”œâ”€â”€ adulti_shadow.csv
â”‚   â”œâ”€â”€ attack_train_from_shadows.csv
â”‚   â”œâ”€â”€ attack_test_from_target.csv
â”‚   â””â”€â”€ shadow_splits_bundle/
â”‚       â””â”€â”€ shadow_splits/
â”‚           â”œâ”€â”€ mia_train_shadows.py
â”‚           â”œâ”€â”€ shadow_01_train.csv / shadow_01_out.csv / shadow_01_indices/
â”‚           â”œâ”€â”€ ...
â”‚           â””â”€â”€ shadow_10_train.csv / shadow_10_out.csv / shadow_10_indices/
â””â”€â”€ README.md


---

## ğŸ› ï¸ Environment

- OS: Linux
- Python: 3.11 (pyenv + venv)
- Framework: PyTorch
- Libraries: scikit-learn, pandas, numpy

CPU-only training was used to keep experiments portable and reproducible.


---

## â–¶ï¸ How to Run (Minimal)

Activate environment:

```bash
source ml_env/bin/activate

Train target model (Version 2):

python model.py


Train shadow models & generate attack training dataset:

python "shadows/shadow_splits_bundle/shadow_splits/mia_train_shadows.py" \
  --splits_dir "shadows/shadow_splits_bundle/shadow_splits" \
  --epochs 10 \
  --batch_size 256 \
  --lr 1e-3 \
  --out_attack_csv "shadows/attack_train_from_shadows.csv"


Generate attack test dataset from target:

python mia_make_attack_test_from_target.py


Train and evaluate attack model:

python attack_model.py
python attack_model_per_class.py

âš ï¸ Notes on Privacy & Publishing

This repository includes personal-data-like attributes (e.g., ssn).
If publishing on a public remote (GitHub/GitLab), keep the repository private or add raw datasets to .gitignore to avoid accidental exposure.

ğŸ§¾ Project Log (Dates)

2026-01-06 (Europe/Rome)

Created adulti_buono.csv and shadows/adulti_shadow.csv partitions

Retrained the target binary classifier on adulti_buono.csv

Confirmed Version 2 target architecture (128â†’64â†’2) and saved adult_mlp_model.pth

2026-01-07 (Europe/Rome)

Used 10 pre-generated shadow splits (shadow_01 â€¦ shadow_10)

Trained 10 shadow models and generated shadows/attack_train_from_shadows.csv (120,660 rows)

Generated shadows/attack_test_from_target.csv using the target train/test split (18,098 rows)

Trained and evaluated attack models (global + per-class); observed AUC â‰ˆ 0.5 (no membership signal)

Last updated: 2026-01-07


---

